---
title: Traffic Data Analysis
output: html_document
---

```{r}
library(ggplot2)
library(dplyr)
library(reshape)
library(reshape2)
library(tidyr)
library(knitr)
library(plyr)
library(BSDA)
```

# Data Processing : identify metrics and dimensions

##First of all importing the data into R

```{r}
by2olak_data = read.csv("all-semi-unique.csv")
str(lapply(by2olak_data, unique), vec.len = 4)
```
## Removal of all the columns related to advertisements

```{r}
by2olak_data = subset(by2olak_data, select=-c(ad.aid,ad.bgcl,ad.bgcls,ad.fncl,ad.fncls,ad.lid,ad.logo,
	ad.logo2x,ad.logoAndroidS,ad.logoAndroidH,ad.cm,ad.url,ad.g))
```

## Removal of columns with constant values
To get a quick idea of the data, a possible way is to get the number of unique values for each column
```{r}
rapply(by2olak_data,function(x)length(unique(x)))
```

### Unique values in rd.img column 
```{r}
unique(by2olak_data['rd.img'])
```
It is obvious that NA corresponds to no image which simply can be false.

```{r}
by2olak_data <- by2olak_data %>% mutate(rd.img = ifelse(is.na(rd.img),FALSE,rd.img))
```

### Unique values in rd.cl column 
```{r}
unique(by2olak_data['rd.cl'])
```
There is only one value so the column can be removed.
```{r}
by2olak_data <- subset( by2olak_data, select = -rd.cl)
```

### Unique values in rd.rp.type column
```{r}
unique(by2olak_data['rd.rp.type'])
```
Same thing like rd.cl, there is only one value which is zero so it can be removed.
```{r}
by2olak_data <- subset(by2olak_data, select = -rd.rp.type)
```

## Working with NAs

The Date is a little bit better than before
```{r}
glimpse(by2olak_data)
```
The 2 columns rd.rp.fullnm & rd.rp.nm are similar from the values of the 2 columns as one is the username
 and the other is the full name of the user which is not very useful		

We can check the number of NAs in each of them
```{r}
sum(is.na(by2olak_data['rd.rp.fullnm']))
sum(is.na(by2olak_data['rd.rp.nm']))
```
It is possible to remove rd.rp.fullnm as it has a lot of NAs and the column does not provide any additional information
```{r}
by2olak_data <- subset( by2olak_data, select = -rd.rp.fullnm)
```
At this point, it is useful to see the number of NAs in each column:
```{r}
rapply(by2olak_data,function(x)sum(is.na(x)))
```
A lot of NAs are there in rd.rp.rpImg & rd.rp.img so we can add a default value for these NAs
```{r}
rapply(by2olak_data,function(x)sum(x == 0 | is.na(x)))
```
Since the number is the same for NAs and for NAs or zeros. We can conclude there are no zero values
 so it can be used as a default value
```{r}
by2olak_data <- by2olak_data %>% mutate(rd.rp.rpImg = ifelse(is.na(rd.rp.rpImg),0,rd.rp.rpImg))
by2olak_data <- by2olak_data %>% mutate(rd.rp.img = ifelse(is.na(rd.rp.img),0,rd.rp.img))
```

Let's see now the number of NAs in each column after cleaning the data.
```{r}
rapply(by2olak_data,function(x)sum(is.na(x)))
```
There are still Columns with NAs, the rd.rp.stid with NAs is actually comments or questioning info for the road.
A value should be given for such a scenario, let's have a look at the values of this column
```{r}
table(by2olak_data['rd.rp.stid'])
```
0 for example is a possible value to be used as they are all from 1 to 10.
```{r}
by2olak_data$rd.rp.stid[is.na(by2olak_data$rd.rp.stid)] <- 0
```

The NAs for the columns after adjustments
```{r}
rapply(by2olak_data,function(x)sum(is.na(x)))
```

For hours and mins of road rd.hr & rd.mn, their NAs can be removed as they are 1507 from all rows, which can be neglected.
```{r}	
by2olak_data <- by2olak_data[!is.na(by2olak_data$rd.hr),]
by2olak_data <- by2olak_data[!is.na(by2olak_data$rd.mn),]
```
Now the only column which contains NAs is rd.stid
```{r}
sum(is.na(by2olak_data['rd.stid']))
```
It can be omited as there are the last rows with NAs and they are around 6% of the whole data
```{r}
by2olak_data <- na.omit(by2olak_data)
```
Now all the columns have no NAs as a value 
```{r}
rapply(by2olak_data,function(x)sum(is.na(x)))
```

## Formatting the Crawl Date

To extract the day itself from data (Sun, Tue, etc.)
```{r}
by2olak_data$day <- gsub("([A-Za-z]+).*", "\\1", by2olak_data$crawl_date)
head(by2olak_data$day)
```
The  crawl_date is the date when this data was crawled in UTC which is 2 hours behind Cairo time), 
The crawl date will be adjusted to be synchronized with Cairo time (GMT+2)

In the R code it will be GMT-2 as the time was behind by 2 hours (-2)
```{r}
by2olak_data$crawl_date <- strptime(by2olak_data$crawl_date, format = "%a %b %d %X UTC %Y", tz = "UTC") %>% as.POSIXct()
by2olak_data$crawl_date <- format(by2olak_data$crawl_date , "%Y-%m-%d-%H-%M-%S", tz="Etc/GMT-2")
head(by2olak_data$crawl_date)
```

To modify the day to be Sunday, Tuesday instead of Sun,Tue, etc.
```{r}
by2olak_data <- by2olak_data %>% mutate(day = weekdays(as.Date(by2olak_data$crawl_date)))
head(by2olak_data$day)
```

Since the Crawl day is not necessarily the day of the report, calculation of the actual day should be done.
```{r}
by2olak_data <- by2olak_data %>% mutate(actual_day = 
	ifelse(by2olak_data$rd.hr < 24, weekdays(as.Date(by2olak_data$crawl_date)),
		ifelse(by2olak_data$rd.hr >= 24 & by2olak_data$rd.hr<= 48,weekdays(as.Date(by2olak_data$crawl_date)+1),
		weekdays(as.Date(by2olak_data$crawl_date)+2))))
data_sample <- by2olak_data[sample(nrow(by2olak_data), 10), ]
kable(data_sample[,c('day','actual_day','rd.hr')])
```

## Additional Columns for adding features

Create columns that split the road name into 2: 

First, Create a duplicate column which will be splited into 2 
```{r}
by2olak_data$rd.nm2 <- by2olak_data$rd.nm
```
Now split the column into 2 columns in which one is the road header and the other one is the path_taken
```{r, warning=FALSE}
by2olak_data <- by2olak_data %>% separate(rd.nm2, c("road_header", "road_path_taken"), ";")  
```

Now let's split the road_path_taken into 2 columns from and to columns
```{r}
by2olak_data <- by2olak_data %>% separate(road_path_taken, c("road_start", "road_destination"), " To ")  
```

Let's see the NAs in the new columns
```{r}
sum(is.na(by2olak_data['road_header']))
sum(is.na(by2olak_data['road_start']))
sum(is.na(by2olak_data['road_destination']))
```
There are NAs in road_start and road_destination as some roads have only header. Default values should replace the NAs.
```{r}
by2olak_data$road_start[is.na(by2olak_data$road_start)] <- "NONE"
by2olak_data$road_destination[is.na(by2olak_data$road_destination)] <- "NONE"
```


Create a column to show the reports origin : GPS or Users (boolean)
```{r}
by2olak_data['gps'] <- (by2olak_data['rd.rp.nm'] == "bey2ollakgps")
```

Create a column to show if the reports are from Annonnoumous Users.
```{r}
by2olak_data['anonymous'] <- (by2olak_data['rd.rp.nm'] == "fa3el kheir")
```

## Reordering columns
```{r}
colnames(by2olak_data)
```

The columns are not in order anymore, it can be fixed by specifying the order we want.
```{r}
by2olak_data <- subset(by2olak_data, select=c(day,actual_day,crawl_date,rd.nm,road_header,road_start,road_destination,rd.ri,
	rd.stid,rd.hr,rd.mn,rd.new,rd.img,rd.strq,rd.cmrq,rd.rp.nm,gps,anonymous,rd.rp.hr,
	rd.rp.mn,rd.rp.stid,rd.rp.cm,rd.rp.cmid,rd.rp.rpImg,rd.rp.img))
colnames(by2olak_data)
```

## Renaming the columns to give them a proper meaning
```{r}
by2olak_data <- rename(by2olak_data, c("rd.nm"="road_name", "rd.ri"="road_route_id","rd.stid"="road_status_id",
 "rd.hr"="road_update_hours_ago","rd.mn"="road_update_mins_ago", "rd.new"="road_new",
 "rd.img"="road_image","rd.strq"="road_status_request", "rd.cmrq"="road_comment_request",
 "rd.rp.nm"="report_username", "rd.rp.hr"="report_update_hours_ago", "rd.rp.mn"="report_update_mins_ago",
 "rd.rp.stid"="report_status_id" , "rd.rp.cm"="report_comment", "rd.rp.cmid"="report_comment_id" ,
 "rd.rp.rpImg"="report_roadimage" , "rd.rp.img"="report_username_image"))
colnames(by2olak_data)
```

## Finally Removal of rows with same comment id
```{r}
by2olak_data <- by2olak_data[!duplicated(by2olak_data$report_comment_id),]
```

Here is the summary after cleaning the data
```{r,eval=F}
summary(by2olak_data)
```
# Descriptive Statistics to investigate the metrics and dimensions.

## Summary Statistics

### Envolvement of Users in the reports :
There are two types of reports (reports by users and automated ones). For the reports submitted by users,
the user can report as "fa3el kheir" which becomes anonymous to by2ollak.

Here are the numbers or automated reports, anonymous ones and finally reports in which the reporter is not anonymous. 
```{r}
nrow(by2olak_data[by2olak_data$gps,])   
nrow(by2olak_data[by2olak_data$anonymous,])  
nrow(by2olak_data[by2olak_data$anonymous == FALSE & by2olak_data$gps== FALSE,]) 
```
For the above results, it is clear that the reports from users are a lot more that the automated ones, although
there is a portion of users that report anonymously.


### Measures of central tendency and spread
At this point, It is known that the status of by2ollak is organised as follows
```{r, echo=FALSE}
status_id <- c(1,2,3,4,5,6,7,8,9,10)
meaning <- c("7alawa", "lazeez", "mashy", "za7ma","mafesh amal","so2al","khatar","7adsa","3otl","ba2ollak eh")
by2ollak_status <- data.frame(status_id, meaning)
kable(by2ollak_status)
```

So for our analysis, it is better to filter the data with status > 5, as the focus is the traffic status for now.
```{r}
by2olak_data_proper_status <- by2olak_data[by2olak_data$road_status_id <= 5,]
by2olak_data_proper_status <- by2olak_data_proper_status[by2olak_data_proper_status$report_status_id <= 5,]
```

Roads status for each day
```{r}
filtered_data <- count(by2olak_data_proper_status, c("actual_day", "road_status_id"))
kable(filtered_data [with(filtered_data , order(road_status_id, desc(freq))),])
```

Districts with highest requests.
```{r}
filtered_data <- count(by2olak_data_proper_status, c("road_header"))
kable(filtered_data [with(filtered_data , order(desc(freq))),])
```

Now let's calculate the mean, median and mode for the important columns which are the road_status_id,
report_status_id, road_update_hours_ago and report_update_hours_ago

First let's implement the function that will compute the mode as it is not implemented in R
```{r}
estimate_mode <- function(x) {
    d <- density(x)
     d$x[which.max(d$y)]
 }
```

#### Mean - Median - Mode
are all ways to describe the average or the central point of the data

#### Standard deviation
expresses by how much the values differ from the mean value(there is the 68–95–99.7 rule) which
is a shorthand to remember the percentage of values that lie within a band around the mean in a normal distribution with
a width of one, two and three standard deviations, respectively; more accurately, 68.27%, 95.45% and 99.73% of the value

#### Variance
shows how the data is different, divergent, or inconsistent.

#### Road Status Id
```{r}
mean(by2olak_data_proper_status$road_status_id)
median(by2olak_data_proper_status$road_status_id)
estimate_mode(by2olak_data_proper_status$road_status_id)
sd(by2olak_data_proper_status$road_status_id)
var(by2olak_data_proper_status$road_status_id)
```

#### Report Status Id
```{r}
mean(by2olak_data_proper_status$report_status_id)
median(by2olak_data_proper_status$report_status_id)
estimate_mode(by2olak_data_proper_status$report_status_id)
sd(by2olak_data_proper_status$report_status_id)
var(by2olak_data_proper_status$report_status_id)
```
It is clear that the median of road status id and report status id are equal, this is due to the fact that the road status
id is actually calculated based on the reports status ids for the road at the time of the request, so the road status id
and the report status id are positively correlated.

```{r}
cor(by2olak_data[c("road_status_id","report_status_id")]) 
```

#### Road Update Hours ago
```{r}
mean(by2olak_data_proper_status$road_update_hours_ago)
median(by2olak_data_proper_status$road_update_hours_ago)
estimate_mode(by2olak_data_proper_status$road_update_hours_ago)
sd(by2olak_data_proper_status$road_update_hours_ago)
var(by2olak_data_proper_status$road_update_hours_ago)
```
All the values approach zero which indicates that the status of the roads are updated regularly. 

#### Report Update Hours ago
```{r}
mean(by2olak_data_proper_status$report_update_hours_ago)
median(by2olak_data_proper_status$report_update_hours_ago)
estimate_mode(by2olak_data_proper_status$report_update_hours_ago)
sd(by2olak_data_proper_status$report_update_hours_ago)
var(by2olak_data_proper_status$report_update_hours_ago)
```
The values are different from the road status and they are not approaching zero which is a result of the inactivity of the
application users during the day. 

## Data Visualization

### Histograms of the most important columns 
```{r, message = FALSE}
data_plot <- melt(subset(by2olak_data, select=c(road_status_id,report_status_id,road_update_hours_ago,road_update_mins_ago,report_update_hours_ago,report_update_mins_ago)))
ggplot(data_plot,aes(x = value)) + 
    facet_wrap(~variable,scales = "free_x") + 
    geom_histogram()
```
The road status id and the report status id histograms are having the same trend as the road status id is calculated base on
the report status id. For the hours for the road, they are biased towards zero and one as the roads are updated regularly
while the hours for reports are still in the first half of the graph but they are scattered unlike in case of roads. 

```{r, message = FALSE}
qplot(as.factor(anonymous), data = by2olak_data)
qplot(as.factor(gps), data = by2olak_data)
```

Most of the users reports with their usernames not anonymously and also the reports are more likely to be reported by users
but there is still a big portion of reports that are automated based on the GPS in the smart phones.

```{r, message = FALSE}
ggplot(data = melt(subset(by2olak_data, select=c(road_status_id, report_status_id))), aes(x=variable, y=value)) + geom_boxplot(aes(fill=variable))

ggplot(by2olak_data, aes(road_status_id)) + 
     geom_histogram(binwidth=1, alpha=0.9) +
     xlab("Roads Status") + ylab("Count") + ggtitle("Road Status Values Distribution")

ggplot(by2olak_data, aes(report_status_id)) + 
     geom_histogram(binwidth=1, alpha=0.9) +
     xlab("Reports Status") + ylab("Count") + ggtitle("Report Status Values Distribution")
```

The median is 10 which is equals to the upper quartile, this is due to the fact that there are a lot of questions and inquiries on the road which can be 
presented by the 2 above plots which show that there are a huge number of reports and road status ids with value 10 which
corresponds to "b2olak eh".


```{r, message = FALSE}
ggplot(data = melt(subset(by2olak_data_proper_status, select=c(road_status_id, report_status_id))), aes(x=variable, y=value)) + geom_boxplot(aes(fill=variable))

ggplot(by2olak_data_proper_status, aes(road_status_id)) + 
     geom_histogram(binwidth=1, alpha=0.9) +
     xlab("Roads Status") + ylab("Count") + ggtitle("Road Status Values Distribution")

ggplot(by2olak_data_proper_status, aes(report_status_id)) + 
     geom_histogram(binwidth=1, alpha=0.9) +
     xlab("Reports Status") + ylab("Count") + ggtitle("Report Status Values Distribution")
```

The median is 2 in road and report status id after filtering rows with status ids greater than 5 in both road and
report status ids, after taking a look at the 2 above plots, it is clear that most of the status ids are equal 2 also from
the box plot, the ids of value 0 and 5 are cosidered outliers as they are very few.


```{r, message = FALSE}
ggplot(by2olak_data[by2olak_data$road_status_id <= 5,] , aes(road_route_id, road_status_id, col = actual_day)) +
  geom_point(alpha = .6) +
  stat_smooth(se = FALSE, size = 1.5, span = .2) +
  scale_x_continuous("road route") +
  scale_y_continuous("road status") +
  scale_color_discrete("Day of Week")
```

```{r, message = FALSE}
ggplot(by2olak_data, aes(report_status_id, group=road_status_id)) + 
     geom_histogram(aes(colour=road_status_id, fill=road_status_id), binwidth=1, alpha=0.9) +
     xlab("Reports Status") + ylab("Count") + ggtitle("Reports Status by Road Status")
```

Here are 2 plots that show the road and report status ids with respect to the day of the update to give an intuition of the
distribution of status ids on each day.

```{r, message = FALSE}
ggplot(by2olak_data, aes(road_status_id, group=actual_day)) + 
    geom_histogram(aes(colour=actual_day, fill=actual_day), binwidth=1, alpha=0.9) +
    xlab("Roads Status") + ylab("Count") + ggtitle("Roads Status per each day")

ggplot(by2olak_data, aes(report_status_id, group=actual_day)) + 
    geom_histogram(aes(colour=actual_day, fill=actual_day), binwidth=1, alpha=0.9) +
    xlab("Reports Status") + ylab("Count") + ggtitle("Reports Status per each day")
```

Since the roads are updated regularly, the mean is nearly equals to 0 which introduces a lot of outliers. In case of reports
the data was biased to the first half as we mentioned before which also introduces outliers but less than that of the roads.
Here, it is shown clearly how the data is distributed and how the outliers are found.

```{r, message = FALSE}
data_plot <- subset(by2olak_data, select=c(actual_day,road_status_id,report_status_id,
road_update_hours_ago,road_update_mins_ago,report_update_hours_ago,report_update_mins_ago))

ggplot(filter(data_plot), aes(x= actual_day, y= road_update_hours_ago )) + 
     geom_boxplot(aes(fill = actual_day)) +
     stat_summary(fun.y=mean, geom="point", shape=23, size=4) + 
     ggtitle("hours since last update")
 ggplot(filter(data_plot), aes(x= actual_day, y= report_update_hours_ago )) + 
     geom_boxplot(aes(fill = actual_day)) +
     stat_summary(fun.y=mean, geom="point", shape=23, size=4) + 
     ggtitle("hours since last update")
```

## Commentary
At this point, we can conclude that there are a lot of status ids of value 10 which is a "b2olak eh" which is a question
or a query, this is one of main problems with this data. After filtering status ids with value greater than 5.
It was clear that most of the reports on roads and the actual road themselves have a status id of 2 which is "lazeez".
From the tables above, it is noticed that friday has the least number of status ids for each value which is an indicator
to the inacitivity of users on this day as it is a holiday and the roads are already "7alawa" which does not require the
application for information.

# Inferential Data Analysis

## Parameter Inference (confidence intervals)
```{r, message = FALSE}
hist(by2olak_data_proper_status$road_status_id)
hist(by2olak_data_proper_status$road_update_hours_ago)
```
From the plots, they are not normally distributed, so sample of means is needed to construct a normally distributed data in
order to be able to get the confidence intervals of theses columns

```{r, message = FALSE}
N=10000
road_status_ids_samples_mean=as.vector(N)
count=1
for (i in 1:N){
  road_status_ids_samples_mean[count] <- mean(sample(by2olak_data_proper_status$road_status_id, 1000, replace = TRUE))
  count=count+1
}
mean(road_status_ids_samples_mean)
sd(road_status_ids_samples_mean)
hist(road_status_ids_samples_mean)
```

The distribution of the Sample Mean is normally distributed since the sample size is 1000 which is greater than 36.
z-test can be used as it is an appropriate test for such scenario to determine and interpret the 95% and 99% confidence interval
of the population mean.

```{r, message = FALSE}
z.test(road_status_ids_samples_mean, sigma.x = sd(road_status_ids_samples_mean), conf.level = 0.95)

2*(pnorm(2,mean(road_status_ids_samples_mean),sd(road_status_ids_samples_mean))-0.5)*100 #confidence for specific number
qnorm((0.95/2)+0.5, 2 ,sd(road_status_ids_samples_mean)) # upper bound
qnorm((1-0.95)/2, 2 ,sd(road_status_ids_samples_mean)) # lower bound

N=10000
report_hours_samples_mean=as.vector(N)
count=1
for (i in 1:N){
  report_hours_samples_mean[count] <- mean(sample(by2olak_data_proper_status$report_update_hours_ago, 1000, replace = TRUE))
  count=count+1
}
mean(report_hours_samples_mean)
sd(report_hours_samples_mean)
hist(report_hours_samples_mean)

z.test(report_hours_samples_mean, sigma.x = sd(report_hours_samples_mean), conf.level = 0.95)

2*(pnorm(1,mean(report_hours_samples_mean),sd(report_hours_samples_mean))-0.5)*100 #confidence for specific number
qnorm((0.95/2)+0.5, 1,sd(report_hours_samples_mean)) # upper bound
qnorm((1-0.95)/2, 1 ,sd(report_hours_samples_mean)) #lower bound
```

## Hypothesis Testing (null hypothesis testing)